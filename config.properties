#############################################
############ GAME-SETTINGS ##################
#############################################
#Agents Performance in 2 Broker Game
#AlzIncz 
#NvPbr 
#AlD 
#Prober 
#Pavlov 
#AlzSame 
#SoftMj 
#Grim 
#Rand 
#TF2T 
#TFT 
#2TFT 
#TFTV2 
#HardMj
#case-study 0 : Round Robin Tournament
#case-study 1 : AgentCoop vs AgentCoop
#case-study 2 : AgentCoop vs AgentDefect
#case-study 3 : AlwaysDefect vs AgentCoop
#case-study 4 : AlwaysDefect vs AlwaysDefect
#case-study 5 : AlwaysDefect vs TitForTat
#case-study 6 : AlwaysCoop vs TitForTat
#case-study 7 : AlwaysDefect vs TitForTatV2
#case-study 8 : RL1Fixed vs AlwaysDefect
#case-study 9 : RL1Fixed vs AlwaysIncrease
#case-study 10 : RLTraining vs SMN1
#case-study 11 : RLTraining vs SMN2
#case-study 12 : RR : AlI, NaiveProber, AlD, DQL1
#case-study 13 : RR : AlI, NaiveProber, AlD, DQL1, Prober
#case-study 14 : RL1Fixed vs SMN1
#case-study 15 : RL2Fixed vs SMN1
#case-study 16: DQTraining vs SMN1
#case-study 17: DQFixedL1 vs SMN1
#case-study 18 : RR : AlI, NaiveProber, AlD, DQL1, Prober, Pavlov
#case-study 19 : RR : AlI, NaiveProber, AlD, DQL1, Prober, Pavlov, AlS
#case-study 20 : RR : AlI, NaiveProber, AlD, DQL1, Prober, Pavlov, AlS, SoftMj
#case-study 21 : RR : DQL1, Prober, Pavlov, AlS, SoftMj
#case-study 22 : Training : DQLTraining vs SMNE2
#case-study 23 : RR : DQL1, Prober, Pavlov, AlS, SoftMj, DQL2
#case-study 24 : Training : DQLTraining vs SMNE2_2
#case-study 25 : RR : DQL1, Prober, Pavlov, AlS, SoftMj, DQL2_2
#case-study 26 : Training : DQLTraining vs SMNE3
#case-study 27 : RR : DQL1, Prober, Pavlov, AlS, SoftMj, DQL2_2, DQL3
#case-study 28 : Training : DQLTraining vs SMNE4
#case-study 29 : RR : DQL1, Prober, Pavlov, AlS, SoftMj, DQL2_2, DQL3, DQ4
#case-study 30 : RR : DQL1, SoftMj, DQL3, DQ4
#case-study 31 : Training : DQLTraining vs SMNE5
#case-study 32 : RR : DQL1, SoftMj, DQL3, DQ4, DQ5
#case-study 33 : RR : DQL1, SoftMj, DQ4, DQ5
#case-study 34 : Training : DQLTraining vs SMNE6
#case-study 35 : RR : DQL1, SoftMj, DQ4, DQ5, DQ6
#case-study 36 : RR : DQL1, SoftMj, DQ4, DQ6
#case-study 37 : RR : SoftMj, DQ4
#case-study 38 : Training : DQLTraining vs SMNE7
#case-study 39 : RR : SoftMj, DQ4, DQ7
#case-study 40 : RR : SoftMj, DQ4, DQ7, Grim
#case-study 41 : Training : DQLTraining vs SMNE8
#case-study 42 : RR : SoftMj, DQ4, DQ7, Grim, DQ8
#case-study 43 : RR : SoftMj, DQ4, DQ7, Grim, DQ8_2
#case-study 44 : Training : DQLTraining vs SMNE9
#case-study 45 : RR : SoftMj, DQ4, DQ7, Grim, DQ8_2, DQ9
#case-study 46 : RR : SoftMj, DQ4, Grim, DQ8_2, DQ9
#case-study 47 : RR : SoftMj, DQ4, Grim, DQ8_2, DQ9, Rand
#case-study 48 : Training : DQLTraining vs SMNE10
#case-study 49 : RR : SoftMj, DQ4, Grim, DQ8_2, DQ9, Rand, DQ10
#case-study 50 : RR : SoftMj, DQ4, Grim, DQ8_2, DQ9, Rand, DQ10, TF2T
#case-study 51 : RR : SoftMj, DQ4, Grim, DQ8_2, DQ9, DQ10, TF2T
#case-study 52 : RR : SoftMj, DQ3, Grim, DQ8_2, DQ9, TF2T
#case-study 53 : Training : DQLTraining vs SMNE11
#case-study 54 : RR : SoftMj, DQ3, Grim, DQ8_2, DQ9, TF2T, DQ11
#case-study 55 : RR : SoftMj, Grim, DQ8_2, DQ9, TF2T, DQ11
#case-study 56 : Training : DQLTraining vs SMNE12
#case-study 57 : RR : SoftMj, Grim, DQ8_2, DQ9, TF2T, DQ11, DQ12
#case-study 58 : RR : SoftMj, Grim, DQ8_2, DQ9, TF2T
#case-study 59 : Training : DQLTraining vs SMNE13
#case-study 60 : RR : SoftMj, Grim, DQ8_2, DQ9, TF2T, DQ13
#case-study 61 : RR : SoftMj, Grim, DQ8_2, DQ9, TF2T, TFT
#case-study 62 : Training : DQLTraining vs SMNE14
#case-study 63 : RR : SoftMj, Grim, DQ8_2, DQ9, TF2T, TFT, DQ14
#case-study 64 : RR : SoftMj, Grim, DQ8_2, TF2T, TFT
#case-study 65 : RR : SoftMj, DQ8_2, TF2T, TFT
#case-study 66 : Training : DQLTraining vs SMNE15
#case-study 67 : RR : SoftMj, DQ8_2, TF2T, TFT, DQ15
#case-study 68 : Training : DQLTraining vs SMNE16
#case-study 69 : RR : SoftMj, DQ8_2, TF2T, TFT, DQ15, DQ16
#case-study 70 : Training : DQLTraining vs SMNE17
#case-study 71 : RR : SoftMj, DQ8_2, TF2T, TFT, DQ15, DQ16, DQ17
#case-study 72 : RR : SoftMj, DQ8_2, TF2T, TFT, DQ15, 2TFT
#case-study 73 : Training : DQLTraining vs SMNE18
#case-study 74 : RR : SoftMj, DQ8_2, TF2T, TFT, DQ15, 2TFT, DQ18
#case-study 75 : RR : DQ8_2, TF2T, TFT, DQ15, 2TFT, DQ18
#case-study 76 : RR : TF2T, TFT, DQ15, 2TFT, DQ18
#case-study 77 : Training : DQLTraining vs SMNE19
#case-study 78 : RR : TF2T, TFT, DQ15, 2TFT, DQ18, DQ19
#case-study 79 : RR : TF2T, TFT, DQ15, 2TFT, DQ18, DQ19, TFTV2
#case-study 80 : RR : TFT, DQ15, 2TFT, DQ18, DQ19, TFTV2
#case-study 81 : RR : TFT, DQ15, 2TFT, DQ19, TFTV2
#case-study 82 : RR : DQ15, 2TFT, DQ19, TFTV2
#case-study 83 : RR : DQ15, 2TFT, TFTV2
#case-study 84 : Training : DQLTraining vs SMNE20
#case-study 85 : RR : DQ15, 2TFT, TFTV2, DQ20
#case-study 86 : RR : DQ15, 2TFT, TFTV2, DQ20, HM
#case-study 87 : RR : DQ15, 2TFT, TFTV2, HM
#case-study 88 : Training : DQLTraining vs SMNE21
#case-study 89 : RR : DQ15, 2TFT, TFTV2, HM, DQ21
#case-study 90 : Training : DQLTraining vs SMNE22
#case-study 91 : RR : DQ15, 2TFT, TFTV2, HM, DQ21, DQ22
#case-study 92 : Training : DQLTraining vs SMNE23
#case-study 93 : RR : DQ15, 2TFT, TFTV2, HM, DQ23
#case-study 94 : RR : 2TFT, TFTV2, HM
case-study=91
#Simulation-time
total-timeslots=168
publication-cycle=6
#cost-function 
#daymult positive for increasing cost-negative for decreasing cost
daymult=0.0
demandmult=0.0
#initail cost 
initcost=0.0
#maximum limit of tariff value
maxtariff=0.5
#############################################
############ CUSTOMER-SETTINGS ##############
#############################################
#inertia 0 (very active) ~ 1 (very lazy)
inertia=0.9
#rationality 0 (irrational) ~ 1 (rational)
rationality=0.9
population=100
#############################################
############ AGENT-SETTINGS #################
#############################################
default-tariff-price=0.25
# Degree of defection i.e. % of actual tariff price
act-change-percentage=0
#############################################
############## LOG-FILE #####################
#############################################
logfilename=RLExistingPopularStrategiesRoundRobin.csv
detailedlogging=false
round=1000
learningrate=0.1
discountfactor=0.99
db-name-training=rl1
rl-training=false
ppts_dscretzd=5
get-nash-eq=true
#############################################
############## Deep Q Learning ##############
#############################################
manual-nash-eq-selection=false
max-dq-agents-allowed=2