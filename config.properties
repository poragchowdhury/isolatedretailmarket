#############################################
############ GAME-SETTINGS ##################
#############################################
#Simulation-time
#maximum limit of tariff value : 0.5
case-study=91
publication-cycle=6
#############################################
############ CUSTOMER-SETTINGS ##############
#############################################
#inertia 0 (very active) ~ 1 (very lazy)
#rationality 0 (irrational) ~ 1 (rational)
inertia=0.0
rationality=1.00
population=100
#############################################
############ AGENT-SETTINGS #################
#############################################
#initail cost : range [0.20~0.10]
maxtariff=0.35
default-tariff-price=0.25
maxunitcost=0.20
initunitcost=0.15
minunitcost=0.10
#############################################
############## LOG-FILE #####################
#############################################
logfilename=RLExistingPopularStrategiesRoundRobin.csv
detailedlogging=false
#############################################
############## Deep Q Learning ##############
#############################################
manual-nash-eq-selection=true
get-nash-eq=true
run-one-iteration=true
max-dq-agents-allowed=2
#############################################
### Deep Q Learning HyperParam ##############
#############################################
discountfactor=0.99
experience-reply=100
batch-size=10
target-dqn-update-freq=100
reward-factor=1.0
min-epsilon=0.1
epsilon-nb-steps-perc=1.0
num-of-hidden-layers=3
num-of-neurons=13
#############################################
################## Game Length ##############
#############################################
total-timeslots=25
dq-training-rounds=3000
test-rounds=1000