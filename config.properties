#############################################
############ GAME-SETTINGS ##################
#############################################
#Simulation-time
#maximum limit of tariff value : 0.5
case-study=91
publication-cycle=6
#############################################
############ CUSTOMER-SETTINGS ##############
#############################################
#inertia 0 (very active) ~ 1 (very lazy)
#rationality 0 (irrational) ~ 1 (rational)
inertia=0.0
rationality=1.0
population=100
#############################################
############ AGENT-SETTINGS #################
#############################################
maxtariff=0.5
default-tariff-price=0.28
#Cost : range [0.20~0.10]
maxunitcost=0.20
initunitcost=0.15
minunitcost=0.10
#############################################
############## LOG-FILE #####################
#############################################
logfilename=RLExistingPopularStrategiesRoundRobin.csv
detailedlogging=false
#############################################
############## Deep Q Learning ##############
#############################################
manual-nash-eq-selection=true
get-nash-eq=true
run-one-iteration=true
max-dq-agents-allowed=2
#############################################
### Deep Q Learning HyperParam ##############
#############################################
discountfactor=0.99
experience-reply=1000
batch-size=100
target-dqn-update-freq=500
reward-factor=0.01
min-epsilon=0.1
epsilon-nb-steps-perc=1.0
num-of-hidden-layers=3
num-of-neurons=13
#############################################
################## Game Length ##############
#############################################
total-timeslots=73
dq-training-rounds=2000
test-rounds=1000