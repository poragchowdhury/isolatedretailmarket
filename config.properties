#############################################
############ GAME-SETTINGS ##################
#############################################
case-study=91
#Simulation-time
total-timeslots=168
publication-cycle=6
#cost-function 
#daymult positive for increasing cost-negative for decreasing cost
daymult=0.0
demandmult=0.0
#initail cost 
initcost=0.0
#maximum limit of tariff value
maxtariff=0.5
#############################################
############ CUSTOMER-SETTINGS ##############
#############################################
#inertia 0 (very active) ~ 1 (very lazy)
inertia=0.9
#rationality 0 (irrational) ~ 1 (rational)
rationality=0.9
population=100
#############################################
############ AGENT-SETTINGS #################
#############################################
default-tariff-price=0.25
# Degree of defection i.e. % of actual tariff price
act-change-percentage=0
#############################################
############## LOG-FILE #####################
#############################################
logfilename=RLExistingPopularStrategiesRoundRobin.csv
detailedlogging=false
dq-training-rounds=1000
test-rounds=1
learningrate=0.1
discountfactor=0.99
db-name-training=rl1
rl-training=false
ppts_dscretzd=5
get-nash-eq=true
#############################################
############## Deep Q Learning ##############
#############################################
manual-nash-eq-selection=true
run-one-iteration=true
max-dq-agents-allowed=2