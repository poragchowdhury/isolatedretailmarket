############ COMMON-SETTINGS ################
case-study=91
total-timeslots=168
publication-cycle=6
dq-training-rounds=100
test-rounds=1
############ CUSTOMER-SETTINGS ##############
#inertia 0 (very active) ~ 1 (very lazy)
inertia=0.9
#rationality 0 (irrational) ~ 1 (rational)
rationality=0.9
population=100
############## Deep Q Learning ##############
manual-nash-eq-selection=false
run-one-iteration=false
max-dq-agents-allowed=2
visualize-model-ui=false
use-actor-critic=false
############ GAME-SETTINGS ################
#cost-function 
#daymult positive for increasing cost-negative for decreasing cost
daymult=0.0
demandmult=0.0
#initail cost 
initcost=0.0
#maximum limit of tariff value
maxtariff=0.5
############ AGENT-SETTINGS #################
default-tariff-price=0.25
# Degree of defection i.e. % of actual tariff price
act-change-percentage=0
############## LOG-FILE #####################
logfilename=RLExistingPopularStrategiesRoundRobin.csv
detailedlogging=false
learningrate=0.1
discountfactor=0.99
db-name-training=rl1
rl-training=false
ppts_dscretzd=5
get-nash-eq=true